# Naruhodo(なるほど)

[![Build Status](https://travis-ci.org/superkerokero/naruhodo.svg?branch=master)](https://travis-ci.org/superkerokero/naruhodo)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyPI version](https://badge.fury.io/py/naruhodo.svg)](https://badge.fury.io/py/naruhodo)

[日本語はこちら](README-ja.md)

Naruhodo is a python library for generating dependency-graph(DG) and knowledge-graph(KG) in networkx format from Japanese text or urls that contains Japanese texts. You can visualize these graphs directly in jupyter notebook or export graphs to JSON file for visualization using external programs.

### Dependency graph (DG)

[Dependency parsing](https://web.stanford.edu/~jurafsky/slp3/14.pdf) is the analysis of [dependency grammar](https://en.wikipedia.org/wiki/Dependency_grammar) on a block of text using computer programs. 
The directed linking nature of dependency grammar makes the result of dependency parsing directed graphs.

Naruhodo generates denpendency graphs(DG) directly from the output of dependency parsing programs. Below is an example of DG generated by naruhodo using the following texts.

```
"一郎は二郎が描いた絵を三郎に贈った。"
"三郎はこの絵を持って市場に行った。"
"市場には人が一杯だ。"
```

![DG generated from texts](img/DG_example.png)

This is an example of DG generated from [Wikipedia-ja: LLVM](https://ja.wikipedia.org/wiki/LLVM)

![DG generated from urls](img/DG_url.png)

### Knowledge graph(KG)

Unlike DG, knowledge-graph(KG) tries to capture the meaningful relationship between different entities. KG is also generated from the output of dependency parsing programs, but the generation follows a different logic.

The methods available to KG is almost identical to those of DG.

Below is an example of KG generated by naruhodo using the following texts.

```
"一郎は二郎が描いた絵を三郎に贈った。"
"三郎はこの絵を持って市場に行った。"
"市場には人が一杯だ。"
```

![KG generated from texts](img/KG_example.png)

This is an example of KG generated from [Wikipedia-ja: LLVM](https://ja.wikipedia.org/wiki/LLVM)

![KG generated from urls](img/KG_url.png)

## Installation

You can install the library directly using pip:

```bash
pip install naruhodo
```

Naruhodo relies on external programs to do Japanese word and dependency parsing, so you need to have corresponding programs installed as well.

Naruhodo is designed to support multiple backend parsers, but currently only the support for `mecab` + `cabocha` is implemented.

For guide on installing `mecab` and `cabocha`, please refer to this page:

[Amazon Linux に MeCab と CaboCha をインストール](https://qiita.com/january108/items/85c80769ea870c190eaa)

Support for other parsers such as `KNP` is planned in the future.

## Tutorial

The tutorial of naruhodo is provided as a `ipynb` file in the tutorial folder. You can view it directly in your browser. This tutorial covers all the main functionalities of naruhodo.

[Tutorial notebook](https://github.com/superkerokero/naruhodo/blob/master/tutorial/Tutorial.ipynb)

## Python-API

The complete python API document for naruhodo can be found here:

[Naruhodo Python API Reference](https://superkerokero.github.io/naruhodo).

This document if generated automatically from source code using [pdoc](https://github.com/BurntSushi/pdoc), so it is up-to-date at any time.

## Development status and some personal comments

Naruhodo is still in development state(especially KG related part), so you might find it outputs weird results sometimes. If you like the idea and want to help improve the library, feel free to create a pull request on github.

Here are some of my thoughts on the development of naruhodo :

* ### Improvement on the quality of generated graph (0.2 ~ 0.5)
    
    As you can see from the source code, naruhodo relies mostly on rule-based system to parse given information.
    And for a subject as large and complex as a language, long-term testing and procedural improvement of the program is neccessary before it can go anywhere.

    Currently the knowledge-graph(KG) generated by naruhodo is below my expectation for large amount of input texts. Improvement will come from furthur examination on varieties of input text and corresponding refinement of parsing logic.

    As a rule-based system, it certainly has its limitations such as completely resolving coreferences. But I believe in the realm of NLP, especially in rudimentary information parsing tasks, rule-based system can be used to make practical applications. Recent advances in statitics-based techniques such as deep learning seem promising. But almost all of these techniques require large amount of labelled data, which is hard to retrieve. The rule-based approach taken here is more or less an Ab Initio way of looking at some NLP problems(which doesn't take any training data before making useful predictions). My hope is that applications like this may at least alleviate the pain of collecting large amount of labelled data by automating some of the tedious tasks. Naruhodo is my personal experiment on how far rule-based system can go in the world of NLP. It may fail to be practically useful, but I am sure it is going to be an interesting journey.

* ### Support for more backends (0.5 ~)
    
    There aren't many Japanese parsing programs available on the internet yet. Aside of `mecab` + `cabocha`, the most usable parsing program seems to be `juman(++)` + `knp`. The output format of `knp` does contain extra useful information and can be more accurate than `cabocha` in some situations. But its output lacks a unified scheme, making it difficult to use. Another important fact is that `juman(++)` + `knp` parsing can be very time consuming compared to `mecab` + `cabocha`, which limits its use cases.

    I am looking into some fast generic libraries like `spaCy` as well. Though Japanese is not the officially supported language for the moment. 

    To summarize, though naruhodo is designed to support multiple backends, since its current focus is Japanese only, adding support for other backends is not a priority.

* ### Support for other languages(?~)
    
    Japanese is the only language naruhodo supports now. Besides my personal interest, I chosen Japanese because it has some unique characteristics that make it both challenging and rewarding. In my opnion, the difficulty regarding Japanese mostly comes from its ambiguity in the expression(for example, the subject is frequently ommited in Japanese) and large amount of word transformations(the same verb can have as many as 10+ forms).

    From a practical point of view, languages such as English and Chinese are in potentially larger demand. So I am thinking about expanding the library to these popular languages in the future, if the rule-based approach taken by naruhodo proves to be usable afterall.

* ### Adding statistics-based approaches(?~)
    
    It seems that everybody is excited about machine learning these days. And I do see huge application potential in techniques like reinforcement learning and generative adversarial models. I do have some thoughts about the applications of these techniques to some specific knowledge retrieval problems. For example, the coreference problem is obviously outside the reach of any rule-based systems. A reinforcement learning approach seems quite attractive in this case(if we have real-time feedbacks from, for example, the users).   
    
    As my understanding of machine learning techniques improves, some statistics-based approaches may be added in the future.

* ### Applications based on DG and KG(new projects)
    
    I think information of DG and KG is especially useful in the realm of automating information retrieval processes. This includes, but not limited to, 
    * automatic text summarization, 
    * knowledge database for Q&A system, 
    * sentiment analysis(combined with word polarity data).

    As the quality of KG generated by naruhodo improves, I will try to apply it to some of these areas.

